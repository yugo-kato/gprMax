# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2015-2025, The University of Edinburgh, United Kingdom.
# Authors: Craig Warren and Antonis Giannopoulos
# This file is distributed under the same license as the gprMax package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: gprMax 3.1.7\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-18 22:01+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: ja\n"
"Language-Team: ja <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../source/benchmarking.rst:5
msgid "Performance benchmarking"
msgstr "パフォーマンスベンチマーク"

#: ../source/benchmarking.rst:7
msgid ""
"This section provides information and results from performance "
"benchmarking of gprMax."
msgstr "このセクションではgprMaxのパフォーマンスベンチマークに関する情報と結果を示します。"

#: ../source/benchmarking.rst:10
msgid "How to benchmark?"
msgstr "ベンチマークの方法は?"

#: ../source/benchmarking.rst:12
msgid ""
"The following simple models (found in the ``tests/benchmarking`` sub-"
"package) can be used to benchmark gprMax on your own system. The models "
"feature different domain sizes (from 100^3 to 450^3 cells) and contain a "
"simple Hertzian dipole source in free space. The following shows an "
"example of the 100^3 cell model:"
msgstr ""
"単純なモデル (サブパッケージ内の ``tests/benchmarking`` ) を使用し"
"あなた自身のシステム上で gprMax のベンチマークを実施できます。"
"異なる領域サイズ (100^3 から 450^3 セル) で"
"自由空間内に単純なヘルツダイポール(Hertzian dipole)ソースを配置したモデルです。"
"以下に、100^3 セル モデルの例を示します。"

#: ../source/benchmarking.rst:20
msgid ""
"Using the following steps to collect and report benchmarking results for "
"each of the models:"
msgstr ""
"以下の手順により各モデルのベンチマーク結果を集めて報告します。"

#: ../source/benchmarking.rst:22
msgid ""
"Run gprMax in benchmarking mode, e.g. ``python -m gprMax "
"tests/benchmarking/bench_100x100x100.in -benchmark``"
msgstr ""
"gprMaxをベンチマークモードで実行します。 例 ``python -m gprMax "
"tests/benchmarking/bench_100x100x100.in -benchmark``"

#: ../source/benchmarking.rst:23
msgid ""
"Use the ``plot_benchmark`` module to create plots of the execution time "
"and speed-up, e.g. ``python -m tests.benchmarking.plot_benchmark "
"tests/benchmarking/bench_100x100x100.npz``. You can combine results into "
"a single plot, e.g. e.g. ``python -m tests.benchmarking.plot_benchmark "
"tests/benchmarking/bench_100x100x100.npz --otherresults "
"tests/benchmarking/bench_150x150x150.npz``."
msgstr ""
" ``plot_benchmark`` モジュールを使用し、実行時間やスピードアップのプロットを作成します。例 ``python -m tests.benchmarking.plot_benchmark "
"tests/benchmarking/bench_100x100x100.npz``. 複数の結果を1つのプロットにまとめることができます。 "
"例 ``python -m tests.benchmarking.plot_benchmark tests/benchmarking/bench_100x100x100.npz --otherresults tests/benchmarking/bench_150x150x150.npz``."

#: ../source/benchmarking.rst:24
msgid ""
"Share your data by emailing us your Numpy archives and plot files to "
"info@gprmax.com"
msgstr ""
"あなたのデータを共有する場合はNumPyアーカイブファイルとプロットファイルを info@gprmax.com までメールで送付してください。"

#: ../source/benchmarking.rst:27
msgid "Results: CPU"
msgstr "結果: CPU"

#: ../source/benchmarking.rst:30
msgid "Mac OS X"
msgstr ""

#: ../source/benchmarking.rst:33 ../source/benchmarking.rst:47
msgid "iMac15,1"
msgstr ""

#: ../source/benchmarking.rst:38
msgid ""
"Execution time and speed-up factor plots for Python/Cython-based gprMax "
"and previous (v.2) C-based code."
msgstr ""

#: ../source/benchmarking.rst:42
msgid ""
"Zero threads indicates that the code was compiled serially, i.e. without "
"using OpenMP."
msgstr ""

#: ../source/benchmarking.rst:44
msgid ""
"The results demonstrate that the Python/Cython-based code is faster, in "
"these two benchmarks, than the previous version which was written in C. "
"It also shows that the performance scaling with multiple OpenMP threads "
"is better with the C-based code. Results from the C-based code show that "
"when it is compiled serially the performance is approximately the same as"
" when it is compiled with OpenMP and run with a single thread. With the "
"Python/Cython-based code this is not the case. The overhead in setting up"
" and tearing down the OpenMP threads means that for a single thread the "
"performance is worse than the serially-compiled version."
msgstr ""

#: ../source/benchmarking.rst:53
msgid "MacPro1,1"
msgstr ""

#: ../source/benchmarking.rst:60
msgid "MacPro3,1"
msgstr ""

#: ../source/benchmarking.rst:67
msgid "Linux"
msgstr ""

#: ../source/benchmarking.rst:70
msgid "Dell PowerEdge R630"
msgstr ""

#: ../source/benchmarking.rst:76
msgid "Lenovo System x3650 M5"
msgstr ""

#: ../source/benchmarking.rst:82
msgid "SuperMicro SYS-7048GR-TR"
msgstr ""

#: ../source/benchmarking.rst:89
msgid "Windows"
msgstr ""

#: ../source/benchmarking.rst:92
msgid "Lenovo T430"
msgstr ""

#: ../source/benchmarking.rst:98
msgid "Dell Z420"
msgstr ""

#: ../source/benchmarking.rst:106
msgid "Results: GPU"
msgstr "結果: GPU"

#: ../source/benchmarking.rst:109
msgid "NVIDIA GPUs"
msgstr ""

#: ../source/benchmarking.rst:111
msgid "The performance metric used to measure the throughput of the solver is:"
msgstr ""

#: ../source/benchmarking.rst:113
#, python-brace-format
msgid "P = \\frac{NX \\cdot NY \\cdot NZ \\cdot NT}{T \\cdot 1 \\times 10^6},"
msgstr ""

#: ../source/benchmarking.rst:117
msgid ""
"where P is the throughput in millions of cells per second; NX, NY, and NZ"
" are the number of cells in domain in the x, y, and z directions; NT is "
"the number of time-steps in the simulation; and T is the runtime of the "
"simulation in seconds."
msgstr ""

