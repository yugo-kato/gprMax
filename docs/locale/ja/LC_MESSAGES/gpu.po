# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2015-2025, The University of Edinburgh, United Kingdom.
# Authors: Craig Warren and Antonis Giannopoulos
# This file is distributed under the same license as the gprMax package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: gprMax 3.1.7\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-18 22:01+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: ja\n"
"Language-Team: ja <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../source/gpu.rst:5
msgid "GPGPU"
msgstr ""

#: ../source/gpu.rst:7
msgid ""
"The most computationally intensive parts of gprMax, which are the FDTD "
"solver loops, can optionally be executed using General-purpose computing "
"on graphics processing units (GPGPU). This has been achieved through use "
"of the NVIDIA CUDA programming environment, therefore a `NVIDIA CUDA-"
"Enabled GPU <https://developer.nvidia.com/cuda-gpus>`_ is required to "
"take advantage of the GPU-based solver."
msgstr ""

#: ../source/gpu.rst:10
msgid "Extra installation steps for GPU usage"
msgstr ""

#: ../source/gpu.rst:12
msgid ""
"The following steps provide guidance on how to install the extra "
"components to allow gprMax to run on your NVIDIA GPU:"
msgstr ""

#: ../source/gpu.rst:14
msgid ""
"Install the `NVIDIA CUDA Toolkit <https://developer.nvidia.com/cuda-"
"toolkit>`_. You can follow the Installation Guides in the `NVIDIA CUDA "
"Toolkit Documentation <http://docs.nvidia.com/cuda/index.html"
"#installation-guides>`_ You must ensure the version of CUDA you install "
"is compatible with the compiler you are using. This information can "
"usually be found in a table in the CUDA Installation Guide under System "
"Requirements."
msgstr ""

#: ../source/gpu.rst:15
msgid ""
"You may need to add the location of the CUDA compiler (:code:`nvcc`) to "
"your user path environment variable, e.g. for Windows :code:`C:\\Program "
"Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vX.X\\bin` or Linux/macOS "
":code:`/Developer/NVIDIA/CUDA-X.X/bin`."
msgstr ""

#: ../source/gpu.rst:16
msgid ""
"Install the pycuda Python module. Open a Terminal (Linux/macOS) or "
"Command Prompt (Windows), navigate into the top-level gprMax directory, "
"and if it is not already active, activate the gprMax conda environment "
":code:`conda activate gprMax`. Run :code:`pip install pycuda`"
msgstr ""

#: ../source/gpu.rst:19
msgid "Running gprMax using GPU(s)"
msgstr ""

#: ../source/gpu.rst:21
msgid ""
"Open a Terminal (Linux/macOS) or Command Prompt (Windows), navigate into "
"the top-level gprMax directory, and if it is not already active, activate"
" the gprMax conda environment :code:`conda activate gprMax`"
msgstr ""

#: ../source/gpu.rst:23
msgid "Run one of the test models:"
msgstr ""

#: ../source/gpu.rst:31
msgid ""
"If you want to select a specific GPU card on your system, you can specify"
" an integer after the :code:`-gpu` flag. The integer should be the NVIDIA"
" CUDA device ID for a specific GPU card. If it is not specified it "
"defaults to device ID 0."
msgstr ""

#: ../source/gpu.rst:35
msgid "Combining MPI and GPU usage"
msgstr ""

#: ../source/gpu.rst:37
msgid ""
"Message Passing Interface (MPI) has been utilised to implement a simple "
"task farm that can be used to distribute a series of models as "
"independent tasks. This is described in more detail in the :ref:`OpenMP, "
"MPI, HPC section <openmp-mpi>`. MPI can be combined with the GPU "
"functionality to allow a series models to be distributed to multiple GPUs"
" on the same machine (node). For example, to run a B-scan that contains "
"60 A-scans (traces) on a system with 4 GPUs:"
msgstr ""

#: ../source/gpu.rst:45
msgid ""
"The argument given with `-mpi` is number of MPI tasks, i.e. master + "
"workers, for MPI task farm. So in this case, 1 master (CPU) and 4 workers"
" (GPU cards). The integers given with the `-gpu` argument are the NVIDIA "
"CUDA device IDs for the specific GPU cards to be used."
msgstr ""

